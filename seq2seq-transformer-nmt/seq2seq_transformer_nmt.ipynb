{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196980bf-7d1b-4557-a6ee-d53686d74b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -U torchdata==0.5.1\n",
    "!pip install -U spacy==3.7.2\n",
    "!pip install -Uqq portalocker==2.7.0\n",
    "!pip install -qq torchtext==0.14.1\n",
    "!pip install -Uq nltk==3.8.1\n",
    "\n",
    "!python -m spacy download de\n",
    "!python -m spacy download en\n",
    "\n",
    "!pip install pdfplumber==0.9.0\n",
    "!pip install fpdf==1.7.2\n",
    "\n",
    "# Download necessary files\n",
    "!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0205EN-SkillsNetwork/Multi30K_de_en_dataloader.py'\n",
    "!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/transformer.pt'\n",
    "!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/input_de.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da731fc-8632-4fa0-9dd3-590fdf944f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from torchtext.datasets import multi30k, Multi30k\n",
    "import torch\n",
    "from typing import Iterable, List\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "# suppress warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1003f-3410-4ddc-b2ad-8c1a8d39542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Order of special symbols\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2d2b30-0ac3-479c-b4fb-0b9dd2e9a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Multi30K dataloader\n",
    "%run Multi30K_de_en_dataloader.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed142477-bd9a-48a1-89b6-642b3682f30e",
   "metadata": {},
   "source": [
    "You've set up data loaders for training and testing. Given the exploratory work, use a batch size of one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59207cbd-f08d-4fb6-99b8-94ebd96a6036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch size and get dataloaders\n",
    "train_dataloader, _ = get_translation_dataloaders(batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d732ad3-0f3f-4091-aefd-3eed758cdcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize data iterator\n",
    "data_itr=iter(train_dataloader)\n",
    "data_itr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a270bde-eb55-43e3-9fe2-a0cd99533af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull a few samples from the data iterator\n",
    "for n in range(1000):\n",
    "    german, english= next(data_itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e64c9d-67cc-47dd-a869-5282b782a74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose data sets\n",
    "german=german.T\n",
    "english=english.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b158cd-1d14-4651-9b3f-50e2d9d8f54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check a few samples from the data iterator\n",
    "for n in range(10):\n",
    "    german, english= next(data_itr)\n",
    "\n",
    "    print(\"sample {}\".format(n))\n",
    "    print(\"german input\")\n",
    "    print(index_to_german(german))\n",
    "    print(\"english target\")\n",
    "    print(index_to_eng(english))\n",
    "    print(\"_________\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bb7562-5058-4dd7-9eba-f9db14f91e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device for GPU, fallback to CPU\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9a2c8f-9330-4e18-9aaa-196fbbe0f303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employ masking to hide future tokens in a sequence\n",
    "def generate_square_subsequent_mask(sz,device=DEVICE):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7029b7f5-7bc9-474c-bab0-d992a11efd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create masks for source and target sequences\n",
    "def create_mask(src, tgt,device=DEVICE):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bd3cdc-4120-4478-acde-2802b02a7be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add positional information to the input tokens\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfbeb53-4580-42a6-af70-132d7bbd37ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed tokens into a vector space\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9341d74a-e36e-4ca0-8287-9a028eec1d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Seq2Seq Transformer model for translation\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "        self.transformer = Transformer(d_model=emb_size,\n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor,\n",
    "                memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        outs =outs.to(DEVICE)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa40cb4-c0fa-4928-be36-9743d92f5200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# define model hyperparameters\n",
    "SRC_LANGUAGE = 'de'\n",
    "TGT_LANGUAGE = 'en'\n",
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 128\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "# instantiate the model\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "# initialize model parameters\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "# move model to device\n",
    "transformer = transformer.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387ee0a7-0fbb-4000-bfb0-22df6caf1e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre-trained model weights\n",
    "transformer.load_state_dict(torch.load('transformer.pt', map_location=DEVICE, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daa8db3-0a69-4e7e-9d72-6bbb05b6aab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull a few samples from the data iterator\n",
    "for n in range(100):\n",
    "    src ,tgt= next(data_itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8464afe-defa-4082-93a8-de9082937c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose source and target\n",
    "print(\"english target\",index_to_eng(tgt))\n",
    "print(\"german input\",index_to_german(src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af827e7-2ad1-4262-b62e-cf4737c9fa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of tokens in source sentence\n",
    "num_tokens = src.shape[0]\n",
    "num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03ab8e3-5382-4af5-a8a7-3ecc96ddd88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create source mask\n",
    "num_tokens = src.shape[0]  \n",
    "src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool).to(DEVICE)\n",
    "src_mask[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652a4c70-f023-4973-a4d9-f8f18d720633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract first column and reshape\n",
    "src_=src[:,0].unsqueeze(1)\n",
    "print(src_.shape)\n",
    "print(src.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a14394-ebe7-4fe7-b9b7-e17186a34bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the source sequence\n",
    "memory = transformer.encode(src_, src_mask)\n",
    "memory.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92b1328-3e26-48d9-866d-0be0ca6dd517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize target sequence with BOS token\n",
    "ys = torch.ones(1, 1).fill_(BOS_IDX).type(torch.long).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad93451-6d44-47da-94bf-fd74d17a793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target mask\n",
    "tgt_mask = (generate_square_subsequent_mask(ys.size(0)).type(torch.bool)).to(DEVICE)\n",
    "tgt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f49364-cfc1-43ef-936e-c16d41028c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed target sequence and encoded source sequence to the decoder\n",
    "out = transformer.decode(ys, memory, tgt_mask)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cecb6e-7662-4ac3-9e3a-1215c12dd6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose output\n",
    "out = out.transpose(0, 1)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08972e36-c02a-4c5e-87a7-f275d54b9a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the logit for the next token\n",
    "logit = transformer.generator(out[:, -1])\n",
    "logit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9f54ae-5d52-4aeb-8372-a3417ac4a5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the index of the highest logit\n",
    "_, next_word_index = torch.max(logit, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a75d66-72b3-4dee-8029-8515f5b3f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the predicted next word index and its corresponding English word\n",
    "print(\"english output:\",index_to_eng(next_word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8443a8ec-3182-44ad-8461-03da2601582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert tensor to scalar\n",
    "next_word_index=next_word_index.item()\n",
    "next_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f76904b-845d-4058-8ef1-fd35a85cbbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append predicted word index to target sequence\n",
    "ys = torch.cat([ys,torch.ones(1, 1).type_as(src.data).fill_(next_word_index)], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db2f4cc-35bf-4d2b-857f-cbfa783ac082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the target mask for the current sequence length\n",
    "tgt_mask = (generate_square_subsequent_mask(ys.size(0)).type(torch.bool)).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8288f720-e66c-4e52-a89b-af55084569b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the current sequence using the transformer and retrieve the output.\n",
    "out = transformer.decode(ys, memory, tgt_mask)\n",
    "out = out.transpose(0, 1)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f88a29e-7b8d-407a-b560-bfa6a82c745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the logit for the next token\n",
    "out[:, -1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6630b2-8922-4486-aa21-d5cf9e5bd9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word probabilities for the last predicted word.\n",
    "prob = transformer.generator(out[:, -1])\n",
    "# Find the word index with the highest probability.\n",
    "_, next_word_index = torch.max(prob, dim=1)\n",
    "# Print the predicted English word.\n",
    "print(\"English output:\", index_to_eng(next_word_index))\n",
    "# Convert the tensor value to a Python scalar.\n",
    "next_word_index = next_word_index.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0c8ca1-62f3-467c-9cdd-fefdcefb65a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the target sequence with the newly predicted word index.\n",
    "ys = torch.cat([ys,torch.ones(1, 1).type_as(src.data).fill_(next_word_index)], dim=0)\n",
    "print(\"english output\",index_to_eng(ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0762a49e-0a55-41dc-8202-9695ec166f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define decoding function using greedy approach\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5cbe73-ef61-4e02-a5db-0d1fd2f45bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create source padding mask\n",
    "src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool).to(DEVICE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80019b7b-a456-42b7-beff-482e18c79686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define maximum length for decoding\n",
    "max_len=src.shape[0]+5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eef9df-d228-4148-88d2-b3d72e5b3252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply greedy decoding to generate the target sequence\n",
    "ys=greedy_decode(transformer, src, src_mask, max_len, start_symbol=BOS_IDX)\n",
    "print(\"english \",index_to_eng(ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d28dc11-bbf2-44cc-8eac-65fdf6bb8bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply greedy decoding to generate the target sequence\n",
    "print(\"english \",index_to_eng(tgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16850b2f-6d6b-43b1-8591-545d17ded070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function with padding index ignored\n",
    "from torch.nn import CrossEntropyLoss\n",
    "loss_fn = CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9181142-e285-472d-a5a2-eef7bff8805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the last token from the target sequence for input\n",
    "tgt_input = tgt[:-1, :]\n",
    "print(index_to_eng(tgt_input))\n",
    "print(index_to_eng(tgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb99aa2-dded-4a27-ab33-51c956a7c2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create masks for source and target sequences\n",
    "src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "print(f\"Shape of src_mask: {src_mask.shape}\")\n",
    "print(f\"Shape of tgt_mask: {tgt_mask.shape}\")\n",
    "print(f\"Shape of src_padding_mask: {src_padding_mask.shape}\")\n",
    "print(f\"Shape of tgt_padding_mask: {tgt_padding_mask.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caf7346-ba05-436d-aec2-b46a24f78a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print target mask and corresponding English words\n",
    "print(tgt_mask)\n",
    "[index_to_eng( tgt_input[t==0])  for t in tgt_mask] #index_to_eng(tgt_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f50dd55-e45e-4704-b3f2-a7f3234da863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logits from forward pass of the transformer model\n",
    "logits = transformer(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "print(\"output shape\",logits.shape)\n",
    "print(\"target shape\",tgt_input.shape)\n",
    "print(\"source shape \",src.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22951870-51d6-4151-a814-c7b4b60a188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the target output by removing the first token in order to ground truth the predictions\n",
    "tgt_out = tgt[1:, :]\n",
    "print(tgt_out.shape)\n",
    "[index_to_eng(t)  for t in tgt_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe145d2-9e1f-4d60-bf53-4d7cdb3c1e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the target output for loss computation\n",
    "tgt_out_flattened = tgt_out.reshape(-1)\n",
    "print(tgt_out_flattened.shape)\n",
    "tgt_out_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c780bd4-9bba-4638-a0ad-9670ccee2f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute loss between predicted logits and ground truth target output\n",
    "[\"input: {} target: {}\".format(index_to_eng( tgt_input[m==0]),index_to_eng( t))  for m,t in zip(tgt_mask,tgt_out)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd80e22-7314-412d-b81c-339812d92e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate loss\n",
    "loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9973a6-2860-460b-909d-abcc1d852f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation function to compute average loss on validation set\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    for src, tgt in val_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06de1480-8f43-4752-b795-9b52d183f04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training function for one epoch\n",
    "def train_epoch(model, optimizer, train_dataloader):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "\n",
    "    # Wrap train_dataloader with tqdm for progress logging\n",
    "    train_iterator = tqdm(train_dataloader, desc=\"Training\", leave=False)\n",
    "    # Iterate over batches in the training dataloader\n",
    "    for src, tgt in train_iterator:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "        src_mask = src_mask.to(DEVICE)\n",
    "        tgt_mask = tgt_mask.to(DEVICE)\n",
    "        src_padding_mask = src_padding_mask.to(DEVICE)\n",
    "        tgt_padding_mask = tgt_padding_mask.to(DEVICE)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "        logits = logits.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "        # Update tqdm progress bar with the current loss\n",
    "        train_iterator.set_postfix(loss=loss.item())\n",
    "\n",
    "    return losses / len(list(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afeb94d-05e1-4002-a7bd-b9d2dde1df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 128\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adae8c16-a93a-4051-9d89-c9dfe40178dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "train_dataloader, val_dataloader = get_translation_dataloaders(batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a64b59c-0fbd-486a-bbba-a413f8ea1ec2",
   "metadata": {},
   "source": [
    "Create a transformer model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6ec9e9-fcf1-4b81-af5b-36a8201184fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Seq2Seq Transformer model\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "transformer = transformer.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885ec650-98d2-4521-943b-df2b8411e39e",
   "metadata": {},
   "source": [
    "Initialize the weights of the transformer model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d1aacf-dc9a-4a6e-9856-53f8904a01c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Adam optimizer\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343c14a4-dd40-4519-8632-8041766c8dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize lists to track training and validation loss\n",
    "TrainLoss=[]\n",
    "ValLoss=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a116c441-c3eb-4061-b6ac-16244bf0c731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop for multiple epochs\n",
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(transformer, optimizer, train_dataloader)\n",
    "    TrainLoss.append(train_loss)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer)\n",
    "    ValLoss.append(val_loss)\n",
    "    print(f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, Epoch time = {(end_time - start_time):.3f}s\")\n",
    "torch.save(transformer.state_dict(), 'transformer_de_to_en_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ff61b8-862c-4833-bcae-b12da486faa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "epochs = range(1, len(TrainLoss) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, TrainLoss, 'r', label='Training loss')\n",
    "plt.plot(epochs,ValLoss, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dce4af-90df-493c-a986-b34f8ae518c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate input sentence into target language\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff29dc-ac12-4b4b-979d-1429b7396886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull a few samples from the data iterator\n",
    "for n in range(5):\n",
    "    german, english= next(data_itr)\n",
    "\n",
    "    print(\"German Sentence:\",index_to_german(german).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\"))\n",
    "    print(\"English Translation:\",index_to_eng(english).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\"))\n",
    "    print(\"Model Translation:\",translate(transformer,index_to_german(german)))\n",
    "    print(\"_________\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a78f75-31d2-488b-88a1-9eb92fd6d039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate BLEU score for the generated translation\n",
    "def calculate_bleu_score(generated_translation, reference_translations):\n",
    "    # convert the generated translations and reference translations into the expected format for sentence_bleu\n",
    "    references = [reference.split() for reference in reference_translations]\n",
    "    hypothesis = generated_translation.split()\n",
    "\n",
    "    # calculate the BLEU score\n",
    "    bleu_score = sentence_bleu(references, hypothesis)\n",
    "\n",
    "    return bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b004d2-eeae-4510-ac84-2b4ddfaa18ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run example translation and calculate BLEU score\n",
    "generated_translation = translate(transformer,\"Ein brauner Hund spielt im Schnee .\")\n",
    "\n",
    "reference_translations = [\n",
    "    \"A brown dog is playing in the snow .\",\n",
    "    \"A brown dog plays in the snow .\",\n",
    "    \"A brown dog is frolicking in the snow .\",\n",
    "    \"In the snow, a brown dog is playing .\"\n",
    "\n",
    "]\n",
    "\n",
    "bleu_score = calculate_bleu_score(generated_translation, reference_translations)\n",
    "print(\"BLEU Score:\", bleu_score, \"for\",generated_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2948ecad-a3f7-4486-a521-94b5b86c894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Translate PDF function \n",
    "import pdfplumber\n",
    "import textwrap\n",
    "from fpdf import FPDF\n",
    "\n",
    "# Translate PDF function\n",
    "def translate_pdf(input_file, translator_model, output_file):\n",
    "    pdf = FPDF(orientation='P', unit='mm', format='A4')\n",
    "    pdf.set_auto_page_break(True, margin=10)\n",
    "    pdf.set_font(family='Courier', size=10)\n",
    "   # Open the input PDF file \n",
    "    with pdfplumber.open(input_file) as input_pdf:\n",
    "        for page in input_pdf.pages:\n",
    "            text_content = page.extract_text()\n",
    "            \n",
    "            # Calculate text width\n",
    "            a4_width_mm = 210\n",
    "            pt_to_mm = 0.35\n",
    "            fontsize_pt = 10\n",
    "            fontsize_mm = fontsize_pt * pt_to_mm\n",
    "            margin_bottom_mm = 10\n",
    "            character_width_mm = 7 * pt_to_mm\n",
    "            width_text = a4_width_mm / character_width_mm\n",
    "            \n",
    "            sentences = text_content.split(\".\")\n",
    "            # Process each sentence\n",
    "            for sentence in sentences:\n",
    "                if sentence.strip():  # Skip empty sentences\n",
    "                    translated_sentence = translate(translator_model, sentence)\n",
    "                    lines = textwrap.wrap(translated_sentence, width_text)\n",
    "                    \n",
    "                    if len(lines) == 0:\n",
    "                        pdf.ln()\n",
    "                    else:\n",
    "                        for wrap in lines:\n",
    "                            pdf.cell(0, fontsize_mm, wrap, ln=1)\n",
    "# Save the translated PDF    \n",
    "    pdf.output(output_file, 'F')  # Save once at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e0f013-2e42-4f28-85a4-6e15c4d7c48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if input PDF file exists, if not download it\n",
    "import os\n",
    "if not os.path.exists('input_de.pdf'):\n",
    "    !wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/input_de.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bcde92-dab8-492a-a523-4bd006cc7841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate the PDF file and save the output\n",
    "input_file_path = \"input_de.pdf\"\n",
    "output_file = 'output_en.pdf'\n",
    "translate_pdf(input_file_path, transformer,output_file)\n",
    "print(\"Translated PDF file is saved as:\", output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "prev_pub_hash": "f583ab330d392f3fbc803e1d84830f575a94e0d7cc0f8b3af49ded45fd51cc14"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
